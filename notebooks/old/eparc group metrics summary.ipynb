{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EParc Group Analysis\n",
    "Eparc is incorrect at:\n",
    "* 002, 003, 016, 019\n",
    "\n",
    "Eparc is missing at:\n",
    "* 011, 004, 101, 102, 111 missing.\n",
    "Removed 18, 19 from Eparc. Removed 001, 006, 018 and 102 from Kinect.\n",
    "\n",
    "Final patient list\n",
    "Compiled: \n",
    "* 005, 007, 008, 009, 010, 013, 014, 015, 017, 020, 021 022 = 15 PD Subjects (7 ON, 8 ON/OFF, 8 OFF)\n",
    "* 103 - 110, 112 - 121 = 8+10 = 18 control subjects\n",
    "\n",
    "Remove the following patients for clinically different:\n",
    "1)\t001\n",
    "2)\t003\n",
    "3)\t004\n",
    "4)\t005\n",
    "5)\t006\n",
    "6)\t008\n",
    "7)\t010\n",
    "8)\t011\n",
    "9)\t013\n",
    "10)\t014\n",
    "11)\t015\n",
    "12)\t017\n",
    "13)\t021\n",
    "\n",
    "\n",
    "- pdon_group = \n",
    "            ['001', '002', '003', '004', '005', '006', '007'\\\n",
    "              '008', '009', '010', '011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']\n",
    "- control_group = \n",
    "            ['101', '102', '103', '104', '105', '106', '107', '108', '109', '110',\\\n",
    "                   '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122']\n",
    "- pdoff_group =\n",
    "            ['011-1', '012-1', '013-1', '014-1', '015-1',\\\n",
    "                    '016-1', '017-1', '018-1', '019-1', '020-1', '021-1', '022-1']\n",
    "- pdonwoff_group = \n",
    "            ['011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']\n",
    "\n",
    "**Table of Contents**\n",
    "- [Preprocessing](#section1)\n",
    "- [Processing Step Length](#section2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import os, csv, json\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import itertools\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "import scipy.io\n",
    "from scipy.spatial import distance as Distance\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "<a id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the subjects with on and off testing were:  ['012', '013', '014', '015', '016', '017', '020', '021', '022']\n"
     ]
    }
   ],
   "source": [
    "######## Get list of files (.mat) we want to work with ########\n",
    "filedir = '../02_StepAnalysis/Processed_StepLength/'\n",
    "files = []\n",
    "debug = 0\n",
    "\n",
    "# get kinect files\n",
    "for file in os.listdir(filedir):\n",
    "    if file.endswith('.mat'):\n",
    "        files.append(file)\n",
    "    \n",
    "######## Load in EVENTS struct to find correct events\n",
    "eparcDir = '../05_Eparc/Processed_Eparc/'\n",
    "eparcfiles = []\n",
    "eparcsubjs = {}\n",
    "\n",
    "# add eparc files\n",
    "for file in os.listdir(eparcDir):\n",
    "    if file.endswith('.mat'):\n",
    "        eparcfiles.append(file)\n",
    "        eparcsubjs[file.split('_')[1]] = file\n",
    "\n",
    "# determine which subjects to analyze (e.g. ones with both eparc and kinect)\n",
    "subjs_to_analyze = []\n",
    "for file in files:\n",
    "    subj = file.split('_')[1]\n",
    "    if subj in eparcsubjs.keys():\n",
    "        subjs_to_analyze.append([file, eparcsubjs[subj]])\n",
    "\n",
    "# subjs_to_analyze = ['005', '007', '008', '009', '010', '013', '014', '015',\\\n",
    "#                     '017', '020', '021', '022', '103', '104', '105', '106', '107',\\\n",
    "#                     '108', '109', '110', '112', '113', '114', '115', '116', '117', '118',\\\n",
    "#                     '119', '120', '121'] \n",
    "subjs_to_analyze = np.array(subjs_to_analyze)     \n",
    "\n",
    "# subjects with both pd on/off\n",
    "onoffsubj = ['012', '013', '014', '015', '016', '017', '020', '021', '022']\n",
    "\n",
    "print \"the subjects with on and off testing were: \", onoffsubj\n",
    "# print \"The files we can analyze are: \"\n",
    "# print subjs_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Subj_001_Step.mat' 'Subj_001_EPARC.mat']\n",
      " ['Subj_002_Step.mat' 'Subj_002_EPARC.mat']\n",
      " ['Subj_003_Step.mat' 'Subj_003_EPARC.mat']\n",
      " ['Subj_005_Step.mat' 'Subj_005_EPARC.mat']\n",
      " ['Subj_006_Step.mat' 'Subj_006_EPARC.mat']\n",
      " ['Subj_007_Step.mat' 'Subj_007_EPARC.mat']\n",
      " ['Subj_008_Step.mat' 'Subj_008_EPARC.mat']\n",
      " ['Subj_009_Step.mat' 'Subj_009_EPARC.mat']\n",
      " ['Subj_010_Step.mat' 'Subj_010_EPARC.mat']\n",
      " ['Subj_012_1_Step.mat' 'Subj_012_EPARC.mat']\n",
      " ['Subj_012_2_Step.mat' 'Subj_012_EPARC.mat']\n",
      " ['Subj_013_1_Step.mat' 'Subj_013_EPARC.mat']\n",
      " ['Subj_013_2_Step.mat' 'Subj_013_EPARC.mat']\n",
      " ['Subj_014_1_Step.mat' 'Subj_014_EPARC.mat']\n",
      " ['Subj_014_2_Step.mat' 'Subj_014_EPARC.mat']\n",
      " ['Subj_015_1_Step.mat' 'Subj_015_EPARC.mat']\n",
      " ['Subj_015_2_Step.mat' 'Subj_015_EPARC.mat']\n",
      " ['Subj_016_1_Step.mat' 'Subj_016_EPARC.mat']\n",
      " ['Subj_016_2_Step.mat' 'Subj_016_EPARC.mat']\n",
      " ['Subj_017_1_Step.mat' 'Subj_017_EPARC.mat']\n",
      " ['Subj_017_2_Step.mat' 'Subj_017_EPARC.mat']\n",
      " ['Subj_018_Step.mat' 'Subj_018_EPARC.mat']\n",
      " ['Subj_019_Step.mat' 'Subj_019_EPARC.mat']\n",
      " ['Subj_020_1_Step.mat' 'Subj_020_EPARC.mat']\n",
      " ['Subj_020_2_Step.mat' 'Subj_020_EPARC.mat']\n",
      " ['Subj_021_1_Step.mat' 'Subj_021_EPARC.mat']\n",
      " ['Subj_021_2_Step.mat' 'Subj_021_EPARC.mat']\n",
      " ['Subj_022_1_Step.mat' 'Subj_022_EPARC.mat']\n",
      " ['Subj_022_2_Step.mat' 'Subj_022_EPARC.mat']\n",
      " ['Subj_103_Step.mat' 'Subj_103_EPARC.mat']\n",
      " ['Subj_104_Step.mat' 'Subj_104_EPARC.mat']\n",
      " ['Subj_105_Step.mat' 'Subj_105_EPARC.mat']\n",
      " ['Subj_106_Step.mat' 'Subj_106_EPARC.mat']\n",
      " ['Subj_107_Step.mat' 'Subj_107_EPARC.mat']\n",
      " ['Subj_108_Step.mat' 'Subj_108_EPARC.mat']\n",
      " ['Subj_109_Step.mat' 'Subj_109_EPARC.mat']\n",
      " ['Subj_110_Step.mat' 'Subj_110_EPARC.mat']\n",
      " ['Subj_112_Step.mat' 'Subj_112_EPARC.mat']\n",
      " ['Subj_113_Step.mat' 'Subj_113_EPARC.mat']\n",
      " ['Subj_114_Step.mat' 'Subj_114_EPARC.mat']\n",
      " ['Subj_115_Step.mat' 'Subj_115_EPARC.mat']\n",
      " ['Subj_117_Step.mat' 'Subj_117_EPARC.mat']\n",
      " ['Subj_118_Step.mat' 'Subj_118_EPARC.mat']\n",
      " ['Subj_119_Step.mat' 'Subj_119_EPARC.mat']\n",
      " ['Subj_120_Step.mat' 'Subj_120_EPARC.mat']\n",
      " ['Subj_121_Step.mat' 'Subj_121_EPARC.mat']]\n"
     ]
    }
   ],
   "source": [
    "print subjs_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eparc has nan at:  ['Subj_002_Step.mat' 'Subj_002_EPARC.mat']\n",
      "Eparc has nan at:  ['Subj_003_Step.mat' 'Subj_003_EPARC.mat']\n",
      "Eparc has nan at:  ['Subj_016_2_Step.mat' 'Subj_016_EPARC.mat']\n",
      "Eparc has nan at:  ['Subj_019_Step.mat' 'Subj_019_EPARC.mat']\n"
     ]
    }
   ],
   "source": [
    "stepLength = {}\n",
    "speed = {}\n",
    "cadence = {}\n",
    "steps = {}\n",
    "\n",
    "for idx, subj in enumerate(subjs_to_analyze):\n",
    "    filesplit = subj[0].split('_')\n",
    "    subj_num = str(filesplit[1])\n",
    "    \n",
    "    try:\n",
    "        onoff = int(filesplit[2])\n",
    "    except:\n",
    "        onoff = None\n",
    "        \n",
    "    # whole file location of each subject's mat file\n",
    "    kinectfile = filedir+subj[0]\n",
    "    eparcfile = eparcDir+subj[1]\n",
    "    \n",
    "    # load in eparc and kinect data structs\n",
    "    kinectdata = scipy.io.loadmat(kinectfile)\n",
    "    kinectdata = kinectdata[sorted(kinectdata.keys())[0]]\n",
    "    eparcdata = scipy.io.loadmat(eparcfile)\n",
    "    eparcdata = eparcdata[sorted(eparcdata.keys())[0]]\n",
    "\n",
    "    ## 01: Load in step lengths and speed as meters  \n",
    "    eparc_steplength = eparcdata['StepLength'][0][0]/100\n",
    "    eparc_speed      = eparcdata['Speed'][0][0]/100\n",
    "    eparc_stepwidth  = eparcdata['StepWidth'][0][0]/100\n",
    "    \n",
    "    kinect_steplength = kinectdata['pks'][0][0]\n",
    "    kinect_speed = kinectdata['velocity'][0][0]\n",
    "    kinect_cadence = kinectdata['cadence'][0][0]\n",
    "    kinect_step = len(kinect_steplength)\n",
    "    \n",
    "    fullset = 1\n",
    "    # if there is an on/off pair dataset, handle differently\n",
    "    if onoff:\n",
    "        subj_num = subj_num + '-' + str(onoff)\n",
    "\n",
    "        if len(eparc_steplength) == 18:\n",
    "            if onoff == 1:\n",
    "                eparc_steplength = eparc_steplength[0:9]\n",
    "                eparc_stepwidth = eparc_stepwidth[0:9]\n",
    "                eparc_speed = eparc_speed[0:9]\n",
    "            elif onoff == 2:\n",
    "                eparc_steplength = eparc_steplength[9:18]\n",
    "                eparc_stepwidth = eparc_stepwidth[9:18]\n",
    "                eparc_speed = eparc_speed[9:18]\n",
    "        else: # not full data set from eparc\n",
    "            fullset = 0\n",
    "    else:\n",
    "        ## 01: Load in step lengths\n",
    "        eparc_steplength = eparcdata['StepLength'][0][0]/100\n",
    "        eparc_speed      = eparcdata['Speed'][0][0]/100\n",
    "        eparc_stepwidth  = eparcdata['StepWidth'][0][0]/100\n",
    "\n",
    "        kinect_stepLength = kinectdata['pks'][0][0]\n",
    "        kinect_velocity = kinectdata['velocity'][0][0]\n",
    "        kinect_cadence = kinectdata['cadence'][0][0]\n",
    "      \n",
    "    flag = 0\n",
    "    if any(np.isnan(eparc_steplength)) or any(np.isnan(eparc_speed)) or any(np.isnan(eparc_stepwidth)):\n",
    "        print \"Eparc has nan at: \", subj\n",
    "        flag = 1\n",
    "    if any(np.isnan(kinect_steplength)) or any(np.isnan(kinect_speed)) or any(np.isnan(kinect_cadence)):\n",
    "        print \"Kinect has nan at: \", subj\n",
    "        flag = 1\n",
    "    \n",
    "    if flag == 0 and fullset == 1:\n",
    "        ## 02: Put all data into nested dictionary\n",
    "        stepLength[subj_num] = {}\n",
    "        speed[subj_num] = {}\n",
    "        cadence[subj_num] = {}\n",
    "        steps[subj_num] = {}\n",
    "\n",
    "        stepLength[subj_num]['kinect'] = kinect_steplength\n",
    "        stepLength[subj_num]['eparc'] = eparc_steplength\n",
    "        speed[subj_num]['kinect'] = kinect_speed\n",
    "        speed[subj_num]['eparc'] = eparc_speed\n",
    "        cadence[subj_num]['kinect'] = kinect_cadence\n",
    "        steps[subj_num]['kinect'] = kinect_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['022-2', '022-1', '021-1', '021-2', '010', '114', '117', '110', '113', '112', '018', '119', '118', '013-2', '013-1', '015-1', '015-2', '016-1', '017-2', '017-1', '014-1', '014-2', '120', '121', '001', '109', '007', '006', '005', '103', '009', '008', '106', '107', '104', '105', '115', '108', '020-1', '020-2']\n"
     ]
    }
   ],
   "source": [
    "print stepLength.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPARC preprocessing version 2\n",
    "preprocessing code for only using the eparc&kinect compiled list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the subjects with on and off testing were:  ['012', '013', '014', '015', '016', '017', '020', '021', '022']\n",
      "['005' '007' '008' '009' '010' '013' '014' '015' '017' '020' '021' '022'\n",
      " '103' '104' '105' '106' '107' '108' '109' '110' '112' '113' '114' '115'\n",
      " '116' '117' '118' '119' '120' '121']\n"
     ]
    }
   ],
   "source": [
    "######## Load in EVENTS struct to find correct events\n",
    "eparcDir = '../05_Eparc/Processed_Eparc/'\n",
    "eparcfiles = []\n",
    "eparcsubjs = {}\n",
    "\n",
    "# add eparc files\n",
    "for file in os.listdir(eparcDir):\n",
    "    if file.endswith('.mat'):\n",
    "        eparcfiles.append(file)\n",
    "        eparcsubjs[file.split('_')[1]] = file\n",
    "\n",
    "subjs_to_analyze = ['005', '007', '008', '009', '010', '013', '014', '015',\\\n",
    "                    '017', '020', '021', '022', '103', '104', '105', '106', '107',\\\n",
    "                    '108', '109', '110', '112', '113', '114', '115', '116', '117', '118',\\\n",
    "                    '119', '120', '121'] \n",
    "subjs_to_analyze = np.array(subjs_to_analyze)     \n",
    "\n",
    "# subjects with both pd on/off\n",
    "onoffsubj = ['012', '013', '014', '015', '016', '017', '020', '021', '022']\n",
    "\n",
    "print \"the subjects with on and off testing were: \", onoffsubj\n",
    "# print \"The files we can analyze are: \"\n",
    "print subjs_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e898df4eaeed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjs_to_analyze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfilesplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msubj_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilesplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "stepLength = {}\n",
    "speed = {}\n",
    "cadence = {}\n",
    "steps = {}\n",
    "\n",
    "for idx, subj in enumerate(subjs_to_analyze):\n",
    "#     filesplit = subj[0].split('_')\n",
    "#     subj_num = str(filesplit[1])\n",
    "    \n",
    "#     try:\n",
    "#         onoff = int(filesplit[2])\n",
    "#     except:\n",
    "#         onoff = None\n",
    "    # check if this subject is an on/off patient\n",
    "    if subj in onoffsubj:\n",
    "        onoff = \n",
    "        \n",
    "    # whole file location of each subject's mat file\n",
    "    kinectfile = filedir+subj[0]\n",
    "    eparcfile = eparcDir+subj[1]\n",
    "    \n",
    "    # load in eparc and kinect data structs\n",
    "    kinectdata = scipy.io.loadmat(kinectfile)\n",
    "    kinectdata = kinectdata[sorted(kinectdata.keys())[0]]\n",
    "    eparcdata = scipy.io.loadmat(eparcfile)\n",
    "    eparcdata = eparcdata[sorted(eparcdata.keys())[0]]\n",
    "\n",
    "    ## 01: Load in step lengths and speed as meters  \n",
    "    eparc_steplength = eparcdata['StepLength'][0][0]/100\n",
    "    eparc_speed      = eparcdata['Speed'][0][0]/100\n",
    "    eparc_stepwidth  = eparcdata['StepWidth'][0][0]/100\n",
    "    \n",
    "    kinect_steplength = kinectdata['pks'][0][0]\n",
    "    kinect_speed = kinectdata['velocity'][0][0]\n",
    "    kinect_cadence = kinectdata['cadence'][0][0]\n",
    "    kinect_step = len(kinect_steplength)\n",
    "    \n",
    "    fullset = 1\n",
    "    # if there is an on/off pair dataset, handle differently\n",
    "    if onoff:\n",
    "        subj_num = subj_num + '-' + str(onoff)\n",
    "\n",
    "        if len(eparc_steplength) == 18:\n",
    "            if onoff == 1:\n",
    "                eparc_steplength = eparc_steplength[0:9]\n",
    "                eparc_stepwidth = eparc_stepwidth[0:9]\n",
    "                eparc_speed = eparc_speed[0:9]\n",
    "            elif onoff == 2:\n",
    "                eparc_steplength = eparc_steplength[9:18]\n",
    "                eparc_stepwidth = eparc_stepwidth[9:18]\n",
    "                eparc_speed = eparc_speed[9:18]\n",
    "        else: # not full data set from eparc\n",
    "            fullset = 0\n",
    "    else:\n",
    "        ## 01: Load in step lengths\n",
    "        eparc_steplength = eparcdata['StepLength'][0][0]/100\n",
    "        eparc_speed      = eparcdata['Speed'][0][0]/100\n",
    "        eparc_stepwidth  = eparcdata['StepWidth'][0][0]/100\n",
    "\n",
    "        kinect_stepLength = kinectdata['pks'][0][0]\n",
    "        kinect_velocity = kinectdata['velocity'][0][0]\n",
    "        kinect_cadence = kinectdata['cadence'][0][0]\n",
    "      \n",
    "    flag = 0\n",
    "    if any(np.isnan(eparc_steplength)) or any(np.isnan(eparc_speed)) or any(np.isnan(eparc_stepwidth)):\n",
    "        print \"Eparc has nan at: \", subj\n",
    "        flag = 1\n",
    "    if any(np.isnan(kinect_steplength)) or any(np.isnan(kinect_speed)) or any(np.isnan(kinect_cadence)):\n",
    "        print \"Kinect has nan at: \", subj\n",
    "        flag = 1\n",
    "    \n",
    "    if flag == 0 and fullset == 1:\n",
    "        ## 02: Put all data into nested dictionary\n",
    "        stepLength[subj_num] = {}\n",
    "        speed[subj_num] = {}\n",
    "        cadence[subj_num] = {}\n",
    "        steps[subj_num] = {}\n",
    "\n",
    "        stepLength[subj_num]['kinect'] = kinect_steplength\n",
    "        stepLength[subj_num]['eparc'] = eparc_steplength\n",
    "        speed[subj_num]['kinect'] = kinect_speed\n",
    "        speed[subj_num]['eparc'] = eparc_speed\n",
    "        cadence[subj_num]['kinect'] = kinect_cadence\n",
    "        steps[subj_num]['kinect'] = kinect_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eparc is incorrect at:\n",
    "* 002, 003, 016, 019\n",
    "\n",
    "Eparc is missing at:\n",
    "* 011, 004, 101, 102, 111 missing.\n",
    "Removed 18, 19 from Eparc. Removed 001, 006, 018 and 102 from Kinect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '005', '006', '007', '008', '009', '010', '013-1', '013-2', '014-1', '014-2', '015-1', '015-2', '016-1', '017-1', '017-2', '018', '020-1', '020-2', '021-1', '021-2', '022-1', '022-2', '103', '104', '105', '106', '107', '108', '109', '110', '112', '113', '114', '115', '117', '118', '119', '120', '121']\n"
     ]
    }
   ],
   "source": [
    "# don't get any of the ones with nan, or not full eparc data\n",
    "print(sorted(stepLength.keys()))\n",
    "\n",
    "allsubjnum = ['005', '007', '008', '009',\\\n",
    "              '010', '012-1', '012-2', '013-1', '013-2', \\\n",
    "              '014-1', '014-2', '015-1', '015-2', '016-1', \\\n",
    "              '017-1', '017-2', '020-1', '020-2', \\\n",
    "              '021-1', '021-2', '022-1', '022-2', '103', \\\n",
    "              '104', '105', '106', '107', '108', '109', \\\n",
    "              '110', '112', '113', '114', '115', '117', '118',\\\n",
    "              '119', '120', '121']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Group EParc\n",
    "<a id=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reject_outliers(data, m = 2.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    return data[s<m]\n",
    "\n",
    "def pretty(d, indent=0):\n",
    "    for key, value in d.iteritems():\n",
    "        print '\\t' * indent + str(key)\n",
    "        if isinstance(value, dict):\n",
    "            pretty(value, indent+1)\n",
    "        else:\n",
    "            print '\\t' * (indent+1) + str(value)\n",
    "            \n",
    "# define patient groups\n",
    "pdon_firstgroup = ['001', '002', '003', '004', '005', '006', '007'\\\n",
    "              '008', '009', '010']\n",
    "control_group = ['101', '102', '103', '104', '105', '106', '107', '108', '109', '110',\\\n",
    "                   '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122']\n",
    "pdoff_group = ['011-1', '012-1', '013-1', '014-1', '015-1',\\\n",
    "                    '016-1', '017-1', '018-1', '019-1', '020-1', '021-1', '022-1']\n",
    "pdon_secondgroup = ['011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put Step Length Eparc For Each Patient into TEXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  001\n",
      "eparc :  0.632 +/- 0.066\n",
      "subject:  005\n",
      "eparc :  0.600 +/- 0.028\n",
      "subject:  006\n",
      "eparc :  0.565 +/- 0.128\n",
      "subject:  007\n",
      "eparc :  0.617 +/- 0.025\n",
      "subject:  008\n",
      "eparc :  0.557 +/- 0.075\n",
      "subject:  009\n",
      "eparc :  0.375 +/- 0.021\n",
      "subject:  010\n",
      "eparc :  0.651 +/- 0.030\n",
      "subject:  013-1\n",
      "eparc :  0.659 +/- 0.024\n",
      "subject:  013-2\n",
      "eparc :  0.841 +/- 0.100\n",
      "subject:  014-1\n",
      "eparc :  0.579 +/- 0.078\n",
      "subject:  014-2\n",
      "eparc :  0.626 +/- 0.020\n",
      "subject:  015-1\n",
      "eparc :  0.559 +/- 0.116\n",
      "subject:  015-2\n",
      "eparc :  0.923 +/- 0.282\n",
      "subject:  016-1\n",
      "eparc :  0.326 +/- 0.133\n",
      "subject:  017-1\n",
      "eparc :  0.511 +/- 0.113\n",
      "subject:  017-2\n",
      "eparc :  0.567 +/- 0.077\n",
      "subject:  018\n",
      "eparc :  0.539 +/- 0.101\n",
      "subject:  020-1\n",
      "eparc :  0.462 +/- 0.073\n",
      "subject:  020-2\n",
      "eparc :  0.536 +/- 0.076\n",
      "subject:  021-1\n",
      "eparc :  0.707 +/- 0.303\n",
      "subject:  021-2\n",
      "eparc :  0.961 +/- 0.386\n",
      "subject:  022-1\n",
      "eparc :  0.296 +/- 0.064\n",
      "subject:  022-2\n",
      "eparc :  0.288 +/- 0.039\n",
      "subject:  103\n",
      "eparc :  0.656 +/- 0.017\n",
      "subject:  104\n",
      "eparc :  0.508 +/- 0.066\n",
      "subject:  105\n",
      "eparc :  0.536 +/- 0.067\n",
      "subject:  106\n",
      "eparc :  0.578 +/- 0.022\n",
      "subject:  107\n",
      "eparc :  0.601 +/- 0.052\n",
      "subject:  108\n",
      "eparc :  0.646 +/- 0.051\n",
      "subject:  109\n",
      "eparc :  0.586 +/- 0.060\n",
      "subject:  110\n",
      "eparc :  0.517 +/- 0.069\n",
      "subject:  112\n",
      "eparc :  0.601 +/- 0.062\n",
      "subject:  113\n",
      "eparc :  0.440 +/- 0.031\n",
      "subject:  114\n",
      "eparc :  0.582 +/- 0.258\n",
      "subject:  115\n",
      "eparc :  0.742 +/- 0.097\n",
      "subject:  117\n",
      "eparc :  0.489 +/- 0.219\n",
      "subject:  118\n",
      "eparc :  0.607 +/- 0.054\n",
      "subject:  119\n",
      "eparc :  0.644 +/- 0.152\n",
      "subject:  120\n",
      "eparc :  0.553 +/- 0.079\n",
      "subject:  121\n",
      "eparc :  0.458 +/- 0.072\n"
     ]
    }
   ],
   "source": [
    "############## PRINTING INTO TABLE FOR EACH PATIENT KINECT AND EPARC STEP LENGTH ############\n",
    "subj_step = {}\n",
    "\n",
    "# lists to store the avge for each grouping\n",
    "pdoff_avge = []\n",
    "pdon_firstavge = []\n",
    "control_avge = []\n",
    "pdon_secondavge = []\n",
    "\n",
    "for subj in sorted(stepLength.keys()):  \n",
    "    subj_step[subj] = {}\n",
    "    # create subplots for steplength and speed\n",
    "    for idx, metric in enumerate(sorted(stepLength[subj].keys())):\n",
    "        if metric == 'eparc':\n",
    "            data_to_print = reject_outliers(stepLength[subj][metric])\n",
    "            data_to_print = stepLength[subj][metric]\n",
    "\n",
    "            avge = \"{0:.3f}\".format(np.mean(data_to_print))\n",
    "            std = \"{0:.3f}\".format(np.std(data_to_print))\n",
    "\n",
    "            subj_step[subj][metric] = [avge, std]\n",
    "\n",
    "            print \"subject: \", subj\n",
    "            print metric, \": \", avge, \"+/-\", std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put Speed Eparc For Each Patient into TEXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  001\n",
      "eparc :  1.460 +/- 1.799\n",
      "subject:  005\n",
      "eparc :  0.784 +/- 0.095\n",
      "subject:  006\n",
      "eparc :  0.825 +/- 0.127\n",
      "subject:  007\n",
      "eparc :  0.721 +/- 0.043\n",
      "subject:  008\n",
      "eparc :  0.722 +/- 0.066\n",
      "subject:  009\n",
      "eparc :  0.561 +/- 0.067\n",
      "subject:  010\n",
      "eparc :  0.745 +/- 0.076\n",
      "subject:  013-1\n",
      "eparc :  0.889 +/- 0.106\n",
      "subject:  013-2\n",
      "eparc :  0.985 +/- 0.077\n",
      "subject:  014-1\n",
      "eparc :  0.735 +/- 0.051\n",
      "subject:  014-2\n",
      "eparc :  0.856 +/- 0.103\n",
      "subject:  015-1\n",
      "eparc :  0.771 +/- 0.078\n",
      "subject:  015-2\n",
      "eparc :  0.947 +/- 0.119\n",
      "subject:  016-1\n",
      "eparc :  0.458 +/- 0.163\n",
      "subject:  017-1\n",
      "eparc :  0.579 +/- 0.098\n",
      "subject:  017-2\n",
      "eparc :  0.647 +/- 0.103\n",
      "subject:  018\n",
      "eparc :  0.613 +/- 0.106\n",
      "subject:  020-1\n",
      "eparc :  0.704 +/- 0.052\n",
      "subject:  020-2\n",
      "eparc :  0.789 +/- 0.042\n",
      "subject:  021-1\n",
      "eparc :  0.620 +/- 0.105\n",
      "subject:  021-2\n",
      "eparc :  0.701 +/- 0.058\n",
      "subject:  022-1\n",
      "eparc :  0.473 +/- 0.073\n",
      "subject:  022-2\n",
      "eparc :  0.479 +/- 0.079\n",
      "subject:  103\n",
      "eparc :  0.866 +/- 0.156\n",
      "subject:  104\n",
      "eparc :  0.867 +/- 0.070\n",
      "subject:  105\n",
      "eparc :  0.608 +/- 0.148\n",
      "subject:  106\n",
      "eparc :  0.749 +/- 0.056\n",
      "subject:  107\n",
      "eparc :  0.645 +/- 0.149\n",
      "subject:  108\n",
      "eparc :  0.947 +/- 0.053\n",
      "subject:  109\n",
      "eparc :  0.787 +/- 0.138\n",
      "subject:  110\n",
      "eparc :  0.651 +/- 0.058\n",
      "subject:  112\n",
      "eparc :  0.732 +/- 0.060\n",
      "subject:  113\n",
      "eparc :  0.758 +/- 0.077\n",
      "subject:  114\n",
      "eparc :  0.650 +/- 0.062\n",
      "subject:  115\n",
      "eparc :  0.743 +/- 0.053\n",
      "subject:  117\n",
      "eparc :  0.627 +/- 0.096\n",
      "subject:  118\n",
      "eparc :  0.736 +/- 0.116\n",
      "subject:  119\n",
      "eparc :  0.877 +/- 0.132\n",
      "subject:  120\n",
      "eparc :  0.563 +/- 0.047\n",
      "subject:  121\n",
      "eparc :  0.510 +/- 0.116\n"
     ]
    }
   ],
   "source": [
    "############## PRINTING INTO TABLE FOR EACH PATIENT KINECT AND EPARC STEP LENGTH ############\n",
    "subj_speed = {}\n",
    "\n",
    "for subj in sorted(speed.keys()):  \n",
    "    subj_speed[subj] = {}\n",
    "    # create subplots for steplength and speed\n",
    "    for idx, modality in enumerate(sorted(speed[subj].keys())):\n",
    "        if modality == 'eparc':\n",
    "            data_to_print = reject_outliers(speed[subj][modality])\n",
    "            data_to_print = speed[subj][modality]\n",
    "\n",
    "            avge = \"{0:.3f}\".format(np.mean(data_to_print))\n",
    "            std = \"{0:.3f}\".format(np.std(data_to_print))\n",
    "\n",
    "            # store average and standard deviation \n",
    "            subj_speed[subj][modality] = [avge, std]\n",
    "\n",
    "            print \"subject: \", subj\n",
    "            print modality, \": \", avge, \"+/-\", std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eparc Groups Summary For Speed, Step Length\n",
    "\n",
    "Now that we finished splitting data into their selective metrics category per patient, we want to group the patients into patient categories and get the group summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creates dictionaries that stores the data for each patient group:\n",
    "pdon\n",
    "control\n",
    "pdoff\n",
    "pdonwoff\n",
    "'''\n",
    "# define patient groups\n",
    "pdon_group = ['001', '002', '003', '004', '005', '006', '007'\\\n",
    "              '008', '009', '010', '011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']\n",
    "control_group = ['101', '102', '103', '104', '105', '106', '107', '108', '109', '110',\\\n",
    "                   '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122']\n",
    "pdoff_group = ['011-1', '012-1', '013-1', '014-1', '015-1',\\\n",
    "                    '016-1', '017-1', '018-1', '019-1', '020-1', '021-1', '022-1']\n",
    "pdonwoff_group = ['011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']\n",
    "\n",
    "# loop through subj_step, subj_stepnum, subj_speed, subj_stepwidth, etc.\n",
    "# all +/- std\n",
    "# lists to store the avge for each grouping\n",
    "pdoff = {}\n",
    "pdon = {}\n",
    "control = {}\n",
    "pdonwoff = {}\n",
    "\n",
    "# initialize nested lists on the grouping dictionaries \n",
    "metrics = ['mean step length', 'var step length', 'mean speed', 'var speed', 'subj']\n",
    "for i in range(0, len(metrics)):\n",
    "    metric = metrics[i]\n",
    "    pdon[metric] = []\n",
    "    pdoff[metric] = []\n",
    "    control[metric] = []\n",
    "    pdonwoff[metric] = []\n",
    "\n",
    "## ONLY DOING KINECT\n",
    "##- 01: Step Length\n",
    "for subj in subj_step.keys():\n",
    "    current_step_mean = float(subj_step[subj]['eparc'][0])\n",
    "    current_step_var = float(subj_step[subj]['eparc'][1])**2\n",
    "    \n",
    "    if subj in pdon_group:\n",
    "        pdon['mean step length'].append(current_step_mean)\n",
    "        pdon['var step length'].append(current_step_var)\n",
    "    if subj in pdonwoff_group:\n",
    "        pdonwoff['mean step length'].append(current_step_mean)\n",
    "        pdonwoff['var step length'].append(current_step_var)\n",
    "    if subj in pdoff_group:\n",
    "        pdoff['mean step length'].append(current_step_mean)\n",
    "        pdoff['var step length'].append(current_step_var)\n",
    "    if subj in control_group:\n",
    "        control['mean step length'].append(current_step_mean)\n",
    "        control['var step length'].append(current_step_var)\n",
    "    \n",
    "##- 02: Speed\n",
    "for subj in subj_speed.keys():\n",
    "    current_speed_mean = float(subj_speed[subj]['eparc'][0])\n",
    "    current_speed_var = float(subj_speed[subj]['eparc'][1])**2\n",
    "    \n",
    "    if subj in pdon_group:\n",
    "        pdon['mean speed'].append(current_speed_mean)\n",
    "        pdon['var speed'].append(current_speed_var)\n",
    "        pdon['subj'].append(subj)\n",
    "    if subj in pdonwoff_group:\n",
    "        pdonwoff['mean speed'].append(current_speed_mean)\n",
    "        pdonwoff['var speed'].append(current_speed_var)\n",
    "        pdonwoff['subj'].append(subj)\n",
    "    if subj in pdoff_group:\n",
    "        pdoff['mean speed'].append(current_speed_mean)\n",
    "        pdoff['var speed'].append(current_speed_var)\n",
    "        pdoff['subj'].append(subj)\n",
    "    if subj in control_group:\n",
    "        control['mean speed'].append(current_speed_mean)\n",
    "        control['var speed'].append(current_speed_var)\n",
    "        control['subj'].append(subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print len(subj_speed.keys())\n",
    "print len(subj_step.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean step length\n",
      "var step length\n",
      "mean speed\n",
      "var speed\n",
      "subj\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a561815aef34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     \"{0:.3f}\".format(np.mean(data_to_print))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpdoff_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' +/- '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{0:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcontrol_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' +/- '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{0:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpdon_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' +/- '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{0:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2885\u001b[0;31m                           out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "pdoff_summary = []\n",
    "pdon_summary = []\n",
    "control_summary = []\n",
    "pdonwoff_summary = []\n",
    "\n",
    "for metric in metrics:\n",
    "    print metric\n",
    "#     \"{0:.3f}\".format(np.mean(data_to_print))\n",
    "    pdoff_summary.append(\"{0:.3f}\".format(np.mean(pdoff[metric])) + ' +/- ' + \"{0:.3f}\".format(np.std(pdoff[metric])))\n",
    "    control_summary.append(\"{0:.3f}\".format(np.mean(control[metric])) + ' +/- ' + \"{0:.3f}\".format(np.std(control[metric])))\n",
    "    pdon_summary.append(\"{0:.3f}\".format(np.mean(pdon[metric])) + ' +/- ' + \"{0:.3f}\".format(np.std(pdon[metric])))\n",
    "    pdonwoff_summary.append(\"{0:.3f}\".format(np.mean(pdonwoff[metric])) + ' +/- ' + \"{0:.3f}\".format(np.std(pdonwoff[metric])))\n",
    "#     metrics.append(metric)\n",
    "print len(control_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean speed': [0.473, 0.62, 0.889, 0.771, 0.458, 0.579, 0.735, 0.704], 'mean step length': [0.296, 0.707, 0.659, 0.559, 0.326, 0.511, 0.579, 0.462], 'var speed': [0.0053289999999999995, 0.011024999999999998, 0.011236, 0.006084, 0.026569000000000002, 0.009604000000000001, 0.0026009999999999996, 0.002704], 'subj': ['022-1', '021-1', '013-1', '015-1', '016-1', '017-1', '014-1', '020-1'], 'var step length': [0.004096, 0.091809, 0.000576, 0.013456000000000001, 0.017689000000000003, 0.012769, 0.006084, 0.0053289999999999995]}\n"
     ]
    }
   ],
   "source": [
    "print pdoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "## write results to file\n",
    "fileName = \"table/eparcPatientGroupsSummary.csv\"\n",
    "\n",
    "with open(fileName, 'w') as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    \n",
    "    writer.writerow(['Metrics Summary', 'PD Off', 'PD On (W/O Off)', 'Control', 'PD On'])\n",
    "    \n",
    "    # loop through each subject and write out the data\n",
    "    for i in range(0, len(control_summary)):\n",
    "        pdoff_data = pdoff_summary[i]\n",
    "        control_data = control_summary[i]\n",
    "        pdon_data = pdon_summary[i]\n",
    "        pdonwoff_data = pdonwoff_summary[i]\n",
    "        metric = metrics[i]\n",
    "\n",
    "        writer.writerow([metric, pdoff_data, pdon_data, control_data, pdonwoff_data])\n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Group EParc Of Clinically Different Patients\n",
    "<a id=\"section3\"></a>\n",
    "\n",
    "Remove the following\n",
    "1)\t001\n",
    "2)\t003\n",
    "3)\t004\n",
    "4)\t005\n",
    "5)\t006\n",
    "6)\t008\n",
    "7)\t010\n",
    "8)\t011\n",
    "9)\t013\n",
    "10)\t014\n",
    "11)\t015\n",
    "12)\t017\n",
    "13)\t021\n",
    "\n",
    "from original list\n",
    "* 001\n",
    "* 005\n",
    "* 006\n",
    "* 007\n",
    "* 008\n",
    "* 009\n",
    "* 010\n",
    "* 013\n",
    "* 014\n",
    "* 015\n",
    "* 016\n",
    "* 017\n",
    "* 020\n",
    "* 021\n",
    "* 022\n",
    "\n",
    "So analyze \n",
    "009, 011, 016, 022\n",
    "\n",
    "First do group summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pats = ['009', '011', '016', '022']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Run TTests For EPARC\n",
    "\n",
    "* PD Off vs. PD On (W/o off)\n",
    "* PD Off vs. PD On\n",
    "* PD On (W/o off) vs. Control\n",
    "* PD On vs. Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean speed', 'mean step length', 'var speed', 'var step length']\n",
      "mean speed\n",
      "mean step length\n",
      "var speed\n",
      "var step length\n",
      "table/eparcPatientGroupsTtest.csv\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# pdoff = {}\n",
    "# pdon_first = {}\n",
    "# control = {}\n",
    "# pdon_second = {}\n",
    "fileName = 'table/eparcPatientGroupsTtest.csv'\n",
    "\n",
    "print pdoff.keys()\n",
    "\n",
    "with open(fileName, 'w') as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(['Metrics Summary', 'PD Off vs PD On', 'PD Off vs PD On (w/ off)',\\\n",
    "                    'PD On vs Control', 'PD On (w/ off) vs Control', 'PD Off vs Control'])\n",
    "    \n",
    "    for metric in pdoff.keys():\n",
    "        testStat, pval = scipy.stats.ttest_ind(pdoff[metric], \\\n",
    "                                              pdon[metric], axis=0, \\\n",
    "                                              equal_var=True)\n",
    "        testStat, pval2 = scipy.stats.ttest_ind(pdoff[metric], \\\n",
    "                                               pdonwoff[metric], axis=0, \\\n",
    "                                               equal_var = True)\n",
    "        testStat, pval3 = scipy.stats.ttest_ind(pdon[metric], \\\n",
    "                                               control[metric], axis=0, \\\n",
    "                                               equal_var = True)\n",
    "        testStat, pval4 = scipy.stats.ttest_ind(pdonwoff[metric], \\\n",
    "                                               control[metric], axis=0, \\\n",
    "                                               equal_var = True)\n",
    "        testStat, pval5 = scipy.stats.ttest_ind(pdoff[metric], \\\n",
    "                                               control[metric], axis=0, \\\n",
    "                                               equal_var = True)\n",
    "    \n",
    "        \n",
    "        writer.writerow([metric, \"{0:.3f}\".format(pval), \\\n",
    "                         \"{0:.3f}\".format(pval2), \\\n",
    "                         \"{0:.3f}\".format(pval3), \\\n",
    "                         \"{0:.3f}\".format(pval4), \\\n",
    "                         \"{0:.3f}\".format(pval5)])\n",
    "        print metric\n",
    "print fileName\n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Variance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean speed', 'mean step length', 'var speed', 'var step length']\n",
      "mean speed\n",
      "mean step length\n",
      "var speed\n",
      "var step length\n",
      "table/eparcPatientGroupsVartest.csv\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# pdoff = {}\n",
    "# pdon_first = {}\n",
    "# control = {}\n",
    "# pdon_second = {}\n",
    "fileName = 'table/eparcPatientGroupsVartest.csv'\n",
    "\n",
    "print pdoff.keys()\n",
    "\n",
    "with open(fileName, 'w') as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(['Metrics Summary', 'PD Off vs PD On', 'PD Off vs PD On (w/ off)',\\\n",
    "                    'PD On vs Control', 'PD On (w/ off) vs Control', 'PD Off vs Control'])\n",
    "    \n",
    "    for metric in pdoff.keys():\n",
    "        F = np.var(pdoff[metric]) / np.var(pdon[metric])\n",
    "        pval = scipy.stats.f.cdf(F, len(pdoff[metric])-1,\\\n",
    "                                           len(pdon[metric])-1)\n",
    "        \n",
    "        F = np.var(pdoff[metric]) / np.var(pdonwoff[metric])\n",
    "        pval2 = scipy.stats.f.cdf(F, len(pdoff[metric])-1, \\\n",
    "                                               len(pdonwoff[metric])-1)\n",
    "        \n",
    "        F = np.var(pdon[metric]) / np.var(control[metric])\n",
    "        pval3 = scipy.stats.f.cdf(F, len(pdon[metric])-1, \\\n",
    "                                               len(control[metric])-1)\n",
    "        \n",
    "        F = np.var(pdonwoff[metric]) / np.var(control[metric])\n",
    "        pval4 = scipy.stats.f.cdf(F, len(pdonwoff[metric]), \\\n",
    "                                               len(control[metric])-1)\n",
    "        \n",
    "        F = np.var(pdoff[metric]) / np.var(control[metric])\n",
    "        pval5 = scipy.stats.f.cdf(F, len(pdoff[metric])-1, \\\n",
    "                                               len(control[metric])-1)\n",
    "    \n",
    "        \n",
    "        writer.writerow([metric, \"{0:.3f}\".format(pval), \\\n",
    "                         \"{0:.3f}\".format(pval2), \\\n",
    "                         \"{0:.3f}\".format(pval3), \\\n",
    "                         \"{0:.3f}\".format(pval4), \\\n",
    "                         \"{0:.3f}\".format(pval5)])\n",
    "        print metric\n",
    "print fileName\n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean speed': [0.479, 0.701, 0.745, 0.985, 0.947, 0.647, 0.856, 1.46, 0.825, 0.784, 0.561, 0.789], 'mean step length': [0.288, 0.961, 0.651, 0.841, 0.923, 0.567, 0.626, 0.632, 0.565, 0.6, 0.375, 0.536], 'var speed': [0.006241, 0.0033640000000000002, 0.005776, 0.005929, 0.014160999999999998, 0.010608999999999999, 0.010608999999999999, 3.236401, 0.016129, 0.009025, 0.004489000000000001, 0.0017640000000000002], 'var step length': [0.001521, 0.14899600000000002, 0.0009, 0.010000000000000002, 0.07952399999999998, 0.005929, 0.0004, 0.0043560000000000005, 0.016384, 0.0007840000000000001, 0.00044100000000000004, 0.005776]}\n",
      "{'mean speed': [0.473, 0.62, 0.889, 0.771, 0.458, 0.579, 0.735, 0.704], 'mean step length': [0.296, 0.707, 0.659, 0.559, 0.326, 0.511, 0.579, 0.462], 'var speed': [0.0053289999999999995, 0.011024999999999998, 0.011236, 0.006084, 0.026569000000000002, 0.009604000000000001, 0.0026009999999999996, 0.002704], 'var step length': [0.004096, 0.091809, 0.000576, 0.013456000000000001, 0.017689000000000003, 0.012769, 0.006084, 0.0053289999999999995]}\n",
      "{'mean speed': [0.479, 0.701, 0.985, 0.947, 0.647, 0.856, 0.789], 'mean step length': [0.288, 0.961, 0.841, 0.923, 0.567, 0.626, 0.536], 'var speed': [0.006241, 0.0033640000000000002, 0.005929, 0.014160999999999998, 0.010608999999999999, 0.010608999999999999, 0.0017640000000000002], 'var step length': [0.001521, 0.14899600000000002, 0.010000000000000002, 0.07952399999999998, 0.005929, 0.0004, 0.005776]}\n"
     ]
    }
   ],
   "source": [
    "print pdon\n",
    "\n",
    "print pdoff\n",
    "\n",
    "print pdonwoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run TTests between On/Off Pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['022-2', '022-1', '021-1', '021-2', '010', '114', '117', '110', '113', '112', '018', '119', '118', '013-2', '013-1', '015-1', '015-2', '016-1', '017-2', '017-1', '014-1', '014-2', '120', '121', '001', '109', '007', '006', '005', '103', '009', '008', '106', '107', '104', '105', '115', '108', '020-1', '020-2']\n",
      "['022-2', '022-1', '021-1', '021-2', '010', '114', '117', '110', '113', '112', '018', '119', '118', '013-2', '013-1', '015-1', '015-2', '016-1', '017-2', '017-1', '014-1', '014-2', '120', '121', '001', '109', '007', '006', '005', '103', '009', '008', '106', '107', '104', '105', '115', '108', '020-1', '020-2']\n"
     ]
    }
   ],
   "source": [
    "pdon_group = ['001', '002', '003', '004', '005', '006', '007'\\\n",
    "              '008', '009', '010', '011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']\n",
    "control_group = ['101', '102', '103', '104', '105', '106', '107', '108', '109', '110',\\\n",
    "                   '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122']\n",
    "pdoff_group = ['011-1', '012-1', '013-1', '014-1', '015-1',\\\n",
    "                    '016-1', '017-1', '018-1', '019-1', '020-1', '021-1', '022-1']\n",
    "pdonwoff_group = ['011-2', '012-2', '013-2', '014-2', '015-2',\\\n",
    "                    '016-2', '017-2', '018-2', '019-2', '020-2', '021-2', '022-2']\n",
    "\n",
    "\n",
    "##- 01: Step Length\n",
    "print stepLength.keys()\n",
    "print steps.keys()\n",
    "fileName = 'table/eparcOnOffTtest.csv'\n",
    "\n",
    "with open(fileName, 'w') as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(['PD On vs. Off Patients', 'Step Length',\\\n",
    "                    'Speed (m/s)'])\n",
    "    \n",
    "    # loop through all possible patients\n",
    "    for idx, subj in enumerate(pdonwoff_group):\n",
    "        if subj in stepLength.keys():\n",
    "            offsubj = pdoff_group[idx]\n",
    "            onsubj = pdonwoff_group[idx]\n",
    "            testStat, stepLength_pval = scipy.stats.ttest_ind(stepLength[onsubj]['eparc'], \\\n",
    "                                                    stepLength[offsubj]['eparc'], axis=0, equal_var=True)\n",
    "            \n",
    "            testStat, speed_pval = scipy.stats.ttest_ind(speed[onsubj]['eparc'], \\\n",
    "                                                    speed[offsubj]['eparc'], axis=0, equal_var=True)\n",
    "\n",
    "            subjName = subj.split('-')[0]\n",
    "            writer.writerow([subjName, \"{0:.3f}\".format(stepLength_pval[0]), \"{0:.3f}\".format(speed_pval[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
